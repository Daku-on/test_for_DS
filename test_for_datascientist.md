---
marp: true
theme: academic
paginate: true
_paginate: false
math: katex
---
<!-- _class: lead -->
# データサイエンティストもテストを書こう

## Test Driven Development for Data-scientists

### Dakuon

#### 2024/02/13

---
<!-- _header: 目次 -->

<div style="font-size: 0.5em">

1. なぜデータサイエンスでテストをしなきゃいけないの？
   1. 重要な観点の整理
   2. MECE (もれなくダブりなく) の実現
   3. 属人性の排除
2. テストってなんだろう
   1. プログラミングにおけるテストとTDD (テスト駆動開発)
   2. テストのメリット・デメリット
   3. ブラックボックステスト
   4. ホワイトボックステスト
3. データサイエンスでどのようにテストを導入するの？
   1. まず主キーチェックから始めよう
4. 実装してみよう
   1. pytestによる実装
5. まとめ
6. 参考文献
7. Appendix
   1. 正常系と異常系

</div>

---
<!-- _header: なぜデータサイエンスでテスト？ -->

**結論**：データサイエンティストもテストを書くべき。

- データ前処理が正しく行われているか、定期的に自動検証できる  
- 解析コードが増えるほど、テストが行動保証となり保守性が向上  
- バグ発見を早めることで、後からの手戻りコストを削減

テストはデータサイエンティストにも他人事ではない！

データサイエンスに必須の前処理が、本当に実装者の想定通りに動いているかを

- 誰の目にもわかるように  
- 目検ではなく、システム的に

示した経験はありますか？あるいは、示したいと思ったことは？

**テストを書きましょう。**

(前処理に限りません。精度モニタリングもある種のCI/CDテストと言えます)

---
<!-- _header: 重要な観点の整理 -->

データ前処理を経て

1. このカラムにはNULLはなくなったはず  
2. このカラムは英数字しか残らないはず  
3. このカラムはHH:MMの形になってるはず

といった観点は事前に全部挙げておくべき。  
結果を確認するために毎回Jupyter Notebookを回すのは骨が折れる。  
**テストで自動化・可視化**すれば、誰が見ても妥当性確認が容易に。

---
<!-- _header: もれない・ダブりない処理の実現 -->
### MECE (もれなくダブりなく) の実現

前処理を大量に書くと、  
- どの箇所でどんな条件が満たされるべきか  
- 処理が重複していないか  
- 特定のケースが抜け落ちていないか

が把握しにくくなります。

テストを書くことで、  
- あらゆる前提・処理条件を列挙し、  
- その条件に沿ったテストケースを用意することで、  

**前処理ロジックがMECEであることを検証可能**になります。  
後から処理を追加しても、テストが重複や抜けを検知する助けとなります。

---
<!-- _header: 属人性の排除 -->

コードレビューで「人によって指摘観点が違う」「後から新たな観点が追加された！」などの経験はありませんか？

**テスト観点を事前に整理・レビュー**し、それらに従うテストコードを書いておけば、**レビュワー依存の変動を最小化**できます。

テストが通っている限り、一定レベルの品質は自動保証。  
(環境依存は`requirements.txt`やpoetry、Dockerで管理すべき)

**テストを書きましょう。**

---
<!-- _header: テスト観点を図解すると... -->

<img src="./img/test_model.png" width="75%" alt="テストフレームワーク">

<!-- footer: 引用元: [図１．テスト観点モデル](https://ww.qbook.jp/column/644.html) -->

---
<!-- _header: テストってなんだろう -->

### テストとは何か？

**結論**: テストはコードが期待通り動くことを確認する行為。  
データサイエンスは探索的な要素が多いが、最終的なロジックは定常化するケースが多く、その際にテストが威力を発揮。

---
<!-- _header: プログラミングにおけるテストとTDD -->

#### プログラミングにおけるテストとTDD (テスト駆動開発)

- **テスト**：コードが期待通り動いているか自動検証する仕組み  
- **TDD**：テストを先に書き、それから機能実装する手法  
  - 利点: 必要な仕様を明確化し、過剰な実装を防ぐ  
  - データサイエンスプロジェクトでも、特定のデータ処理結果を保証するテストを最初に書くことで、仕様ブレを防止

---
<!-- _header: テストのメリット・デメリット -->

### テストのメリット・デメリット

**メリット**:  
- バグ早期発見による手戻り削減  
- コード品質向上  
- 後から触る人が安心して改変できる

**デメリット**:  
- 初期構築コスト (テスト環境準備、ケース設計)  
- 設計や仕様変更時にテストの更新が必要

---
<!-- _header: ブラックボックステスト -->

### ブラックボックステスト

- 内部実装は考えず、入力と出力の関係のみで正当性を評価  
- データサイエンスでの前処理：  
  - 入力データを与え、想定出力形式・値が得られるか検証  
- 例: 入力にNULLが含まれたら処理後にはNULLがなくなるか？

---
<!-- _header: ホワイトボックステスト -->

### ホワイトボックステスト

- 内部実装を考慮したテスト手法  
- コードの分岐・ループを網羅的にテストし、意図しない動きを検出  
- データサイエンスではモデル内部ロジックの特定部分（前処理関数の特定分岐）を網羅的にテスト可能

---
<!-- _header: データサイエンスでどのようにテストを導入するの？ -->
### データサイエンスプロジェクトへのテスト導入

- 分析環境はNotebook中心→最終的なETLや特徴量生成処理はモジュール化しテスト可能な状態に  
- 処理対象となるテーブルやデータフレームがどうあるべきか、前処理段階で定義しテスト化

#### まず主キーチェックから始めよう

- データの主キーがユニークであることは前提条件の一つ  
- テストで主キーに重複がないか毎回確認  
- 主キーの整合性が保証されれば、以降の前処理・特徴量生成の信頼性が向上

---
<!-- _header: 実装してみよう -->
### 実装してみよう (pytestによる実装)

Pythonでのデータ処理 (pandas) とpytestを用いてテスト  
ここでは主キー重複チェックの例を示します

```python
# テスト用サンプルコード
# タイプアノテーションを利用
# 各変数は新しい行に分ける
# ダブルクォートを使用
# 各変数の最後にカンマをつける

import pandas as pd
import pytest

@pytest.fixture
def sample_df() -> pd.DataFrame:
    """サンプルDataFrameを返すフィクスチャ"""
    sample_data: dict = {
        "id": [1,2,2,3,],
        "value": ["A","B","C","D",],
    }
    df: pd.DataFrame = pd.DataFrame(sample_data)
    return df

def test_unique_key(sample_df: pd.DataFrame) -> None:
    """主キー"id"のユニーク性をテスト"""
    # id列に重複がないことをテスト
    duplicated_ids: pd.Series = sample_df["id"].duplicated()
    assert not duplicated_ids.any(), "id列に重複が存在します。"
```

- `pytest`コマンドでテスト実行可能  
- エラー時にはメッセージ表示、通れば静かにパス

---
<!-- _header: まとめ -->
### まとめ

**結論**: データサイエンティストもテストを書くべき。  
- テストは前処理やモデル構築の品質保証を支える仕組み  
- MECEなテスト設計で漏れ・ダブりを防ぎ、属人性を排除  
- ブラックボックス／ホワイトボックス両面からの検証が可能  
- 最初は主キーチェックなど基本的なテストから導入を始めよう

テストが整備されることで、コード改変時の安心感が増し、生産性向上を支えます。

---
<!-- _header: 参考文献 -->

1. [テストの観点とは？使いやすいテスト観点リストの構造・整え方を解説](https://www.qbook.jp/column/644.html)

---
<!-- _header: Appendix 正常系と異常系 -->

### Appendix: 正常系と異常系

- **正常系テスト**：想定された正しい入力に対して期待通りの結果になるかをテスト  
  - 例: 正しい型・範囲のデータが入力された際、期待した変換が行われるか

- **異常系テスト**：想定外の入力やエラー状態に対し、適切なエラー処理やハンドリングが行われるかをテスト  
  - 例: NULL値や異常な日付フォーマットが入力された際に、明示的な例外を出すか、定義済みの処理が機能するか

異常系テストをしっかり行うことで、データ品質問題を早期検出し、安定した分析環境を保つことができます。
